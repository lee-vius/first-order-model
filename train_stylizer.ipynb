{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "565f48b0",
   "metadata": {},
   "source": [
    "# Training for Stylizer module\n",
    "This notebook will handle the training the stylizer module."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76182036",
   "metadata": {},
   "source": [
    "## Load Pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce87f152",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "import os, sys\n",
    "import yaml\n",
    "from argparse import ArgumentParser\n",
    "from time import gmtime, strftime\n",
    "from shutil import copy\n",
    "\n",
    "from frames_dataset import FramesDataset\n",
    "\n",
    "from modules.generator import OcclusionAwareGenerator # LCH: refer here for generator\n",
    "from modules.discriminator import MultiScaleDiscriminator # LCH: refer here for discriminator\n",
    "from modules.keypoint_detector import KPDetector # LCH: refer here for key point detector\n",
    "\n",
    "import torch\n",
    "\n",
    "from train import train # LCH: For training process, everything in this module\n",
    "from reconstruction import reconstruction\n",
    "from animate import animate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18466946",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/levius/conda/anaconda3/envs/firOrder/lib/python3.6/site-packages/ipykernel_launcher.py:4: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "config_path = \"config/anim-256.yaml\"\n",
    "with open(config_path) as f:\n",
    "        # read in the config file\n",
    "        config = yaml.load(f) # config file contains code directions, including training details\n",
    "\n",
    "checkpoint_path = \"pre_trains/vox-cpk.pth.tar\"\n",
    "log_dir = \"MyLog/\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.mkdir(log_dir)\n",
    "# Copy the config file (*.yaml) into the logging path\n",
    "if not os.path.exists(os.path.join(log_dir, os.path.basename(config_path))):\n",
    "    copy(config_path, log_dir)\n",
    "\n",
    "# initialize generator\n",
    "generator = OcclusionAwareGenerator(**config['model_params']['generator_params'],\n",
    "                                        **config['model_params']['common_params'])\n",
    "# initialize discriminator\n",
    "discriminator = MultiScaleDiscriminator(**config['model_params']['discriminator_params'],\n",
    "                                            **config['model_params']['common_params'])\n",
    "# initialize kp detector\n",
    "kp_detector = KPDetector(**config['model_params']['kp_detector_params'],\n",
    "                             **config['model_params']['common_params'])\n",
    "\n",
    "# If GPU Available, adapt to it\n",
    "if torch.cuda.is_available():\n",
    "    generator.to(0)\n",
    "    discriminator.to(0)\n",
    "    kp_detector.to(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cef3da41-9020-4ad1-a0cf-98a263a7de85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the pretrained modules\n",
    "from logger import Logger\n",
    "\n",
    "train_params = config['train_params']\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    # remember to adapt to cpu version\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))\n",
    "else:\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "\n",
    "generator.load_state_dict(checkpoint['generator'])\n",
    "discriminator.load_state_dict(checkpoint['discriminator'])\n",
    "kp_detector.load_state_dict(checkpoint['kp_detector'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1c0bd7-5ec6-418c-8e9a-b76c52cf4859",
   "metadata": {},
   "source": [
    "## Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83c3ca21-e18a-4060-98a9-6cab2aad3e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use predefined train-test split.\n",
      "Dataset size: 1080, repeat number: 4\n",
      "Repeated Dataset size: 1080, repeat number: 4\n"
     ]
    }
   ],
   "source": [
    "from frames_dataset import DatasetRepeater\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "# load original target data\n",
    "frame_dataset = FramesDataset(is_train=True, **config['dataset_params'])\n",
    "print(\"Dataset size: {}, repeat number: {}\".format(len(dataset), config['train_params']['num_repeats']))\n",
    "\n",
    "if 'num_repeats' in train_params or train_params['num_repeats'] != 1:\n",
    "    # Augment the dataset according to \"num_reapeat\"\n",
    "    frame_dataset = DatasetRepeater(dataset, train_params['num_repeats'])\n",
    "    print(\"Repeated Dataset size: {}, repeat number: {}\".format(len(dataset), config['train_params']['num_repeats']))\n",
    "\n",
    "dataloader = DataLoader(frame_dataset, batch_size=train_params['batch_size'], shuffle=True, num_workers=2, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f814d334-3a9a-4ebb-a67f-ca0a1e27b0c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
